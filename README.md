# PRISM â€” Precision Document Intelligence

> Transform any PDF into an intelligent knowledge base with forensic citation accuracy.

PRISM is a production-grade AI document Q&A system. Upload any PDF, ask questions in plain English, and receive verified answers pinned to the exact paragraph they came from â€” with a confidence score on every response.

Built for legal teams, compliance officers, researchers, and anyone who needs to extract precise, verifiable information from complex documents.

---

## Live Demo

ğŸ”— **[prism.vercel.app](https://https://prism-mu-one.vercel.app/)**

---

## What Makes PRISM Different

Most AI document tools give you summaries. PRISM gives you **verified answers**.

| Feature | PRISM | Typical RAG tool |
|---|---|---|
| Search method | Hybrid (Vector + BM25 + RRF) | Vector only |
| Answer validation | Multi-pass self-critique | Single pass |
| Citation accuracy | Exact paragraph, clickable | Page reference only |
| Confidence scoring | Per-answer score | None |
| Dark mode | âœ… | Rarely |
| Multi-document | âœ… | Rarely |

---

## Architecture

### The PRISM Pipeline

Every query runs through a four-stage pipeline:

```
PDF Upload
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Adaptive Ingestion        â”‚
â”‚  â€¢ AI document analysis             â”‚
â”‚  â€¢ Structure-aware chunking         â”‚
â”‚  â€¢ 1536-dim vector embeddings       â”‚
â”‚  â€¢ BM25 full-text index             â”‚
â”‚  â€¢ AI metadata enrichment           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Hybrid Search             â”‚
â”‚  â€¢ Vector search (pgvector/HNSW)    â”‚
â”‚  â€¢ BM25 keyword search (tsvector)   â”‚
â”‚  â€¢ Reciprocal Rank Fusion (RRF)     â”‚
â”‚  â€¢ Deduplication                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: Multi-Pass Reasoning      â”‚
â”‚  â€¢ Cross-encoder re-ranking         â”‚
â”‚  â€¢ Answer generation (GPT-4o)       â”‚
â”‚  â€¢ Self-critique validation         â”‚
â”‚  â€¢ Confidence scoring               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 4: Verified Answer           â”‚
â”‚  â€¢ Answer + confidence score        â”‚
â”‚  â€¢ Clickable citations              â”‚
â”‚  â€¢ PDF viewer jump-to-page          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Hybrid Search â€” Why Both?

**Vector search** finds semantically similar content. Ask "what are the penalties?" and it finds "consequences of breach" even without the word "penalties."

**BM25 search** finds exact keyword matches. Critical for legal and technical documents where precise terminology matters â€” "Section 4.2(b)" must match exactly.

**Reciprocal Rank Fusion (RRF)** combines both result sets into a single ranked list using the formula `score = Î£ 1/(k + rank_i)` where `k=60`. This consistently outperforms either method alone.

### Multi-Pass Reasoning â€” Why Not Single-Pass?

Single-pass RAG generates an answer and stops. PRISM runs three passes:

1. **Initial answer** â€” generated from the top 5 retrieved chunks
2. **Self-critique** â€” a second model call reviews the answer against the source material, checking for hallucinations and unsupported claims
3. **Revised answer** â€” if the critique flags issues, the answer is regenerated with explicit corrections

The confidence score reflects the critique's assessment, not just the model's self-reported certainty.

---

## Tech Stack

| Layer | Technology |
|---|---|
| Framework | Next.js 16 + Turbopack |
| UI | React 19, Tailwind CSS v4 |
| Database | Supabase (PostgreSQL) |
| Vector search | pgvector (HNSW index) |
| Full-text search | PostgreSQL tsvector (GIN index) |
| AI | OpenAI GPT-4o + text-embedding-3-small |
| Auth | Supabase Auth (Email + Google OAuth) |
| Storage | Supabase Storage (private bucket) |
| Deployment | Vercel |
| PDF parsing | pdf-parse (server), react-pdf (client) |
| Chunking | LangChain RecursiveCharacterTextSplitter |

---

## Security Architecture

PRISM is built security-first. Every data access point enforces the same ownership rule: **you can only access your own data.**

### Three enforcement layers (defence in depth):

**1. Supabase Row Level Security (RLS)**
Every table has RLS enabled with per-operation policies. At the database level, `auth.uid() = user_id` is enforced on every SELECT, INSERT, UPDATE, and DELETE. Even if application code is bypassed, the database rejects unauthorised access.

**2. Application ownership checks**
API routes explicitly verify `document.user_id === session.user.id` before returning data â€” belt-and-suspenders alongside RLS.

**3. Search-level scoping**
Both vector and BM25 PostgreSQL RPC functions accept `filter_user_id` â€” search results are scoped to the authenticated user's chunks even at the query level.

### Auth flow
- Supabase Auth with email/password and Google OAuth
- Sessions managed via HTTP-only cookies (SSR-safe via `@supabase/ssr`)
- Next.js proxy (middleware) refreshes tokens on every request
- OAuth callback at `/auth/callback` exchanges code for session server-side

---

## Database Schema

```sql
-- Core tables
documents        (id, user_id, name, file_url, file_size_bytes,
                  page_count, document_type, complexity_score,
                  has_toc, key_entities, status, error_message,
                  created_at, updated_at)

document_chunks  (id, user_id, document_id, content, chunk_index,
                  metadata, embedding, ai_summary, keywords,
                  semantic_category)

chat_messages    (id, user_id, document_id, role, content,
                  confidence, citations, created_at)

-- Supporting tables
profiles         (id, email, display_name, avatar_url,
                  created_at, updated_at)

analytics_logs   (id, user_id, document_id, event_type,
                  query_text, vector_weight, bm25_weight,
                  tokens_used, estimated_cost, confidence_score,
                  feedback, response_time_ms, created_at)
```

---

## Getting Started (Local Development)

### Prerequisites

- Node.js 18+
- A Supabase project
- An OpenAI API key
- A Google Cloud project with OAuth credentials (for Google sign-in)

### 1. Clone and install

```bash
git clone https://github.com/YOUR_USERNAME/prism.git
cd prism
npm install
```

### 2. Environment variables

```bash
cp .env.example .env.local
```

Fill in `.env.local`:

```bash
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
OPENAI_API_KEY=sk-your-openai-key
NEXT_PUBLIC_SITE_URL=http://localhost:3000
```

### 3. Database setup

Run the migrations in order in your Supabase SQL editor:

```
sql/phase-5.2-schema.sql      â€” tables, RLS policies, triggers
sql/phase-5.2-rpc-update.sql  â€” hybrid search RPC functions
sql/phase-5.3-indexes.sql     â€” performance indexes
```

### 4. Enable Google OAuth (optional)

1. Create OAuth credentials in Google Cloud Console
2. Add `https://your-project.supabase.co/auth/v1/callback` as an authorised redirect URI
3. Add the Client ID and Secret in Supabase â†’ Authentication â†’ Providers â†’ Google

### 5. Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000).

---

## First Run Guide

### Uploading your first document

1. **Sign up** at `/register` â€” email/password or Google
2. **Upload a PDF** â€” drag and drop or click the upload zone on the home page
3. **Wait for processing** â€” PRISM runs 7 pipeline stages (typically 30â€“120 seconds depending on document size)
4. **Start chatting** â€” you're automatically navigated to the split-screen workspace

### The split-screen workspace

The workspace has two panels:

**Left panel â€” PDF Viewer**
Your document rendered in-browser. Navigate pages using the controls. When you click a citation in chat, the viewer jumps to that exact page automatically.

**Right panel â€” Chat Interface**
Ask questions in plain English. Each answer includes:
- The answer text
- Numbered citations (click any to jump to that page in the PDF)
- A confidence score (High / Good / Moderate)

### Tips for best results

- **Be specific** â€” "What is the liability cap in Section 8?" gets better results than "what are the limits"
- **Use document terminology** â€” the BM25 engine rewards exact term matches
- **Check confidence scores** â€” scores below 70% indicate the answer may be incomplete
- **Multiple documents** â€” use the document selector in the chat header to switch between documents without leaving the workspace
- **Export** â€” click the download icon to export the full conversation as Markdown

---

## Project Structure

```
prism/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/              # Auth pages â€” login, register
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â””â”€â”€ register/
â”‚   â”œâ”€â”€ api/                 # API routes
â”‚   â”‚   â”œâ”€â”€ chat/            # Q&A pipeline
â”‚   â”‚   â”œâ”€â”€ documents/       # Document CRUD
â”‚   â”‚   â”œâ”€â”€ ingest/          # Ingestion trigger
â”‚   â”‚   â”œâ”€â”€ search/          # Search endpoint
â”‚   â”‚   â””â”€â”€ upload/          # File upload
â”‚   â”œâ”€â”€ auth/callback/       # OAuth callback handler
â”‚   â”œâ”€â”€ chat/                # Split-screen workspace
â”‚   â”œâ”€â”€ layout.tsx           # Root layout + metadata
â”‚   â””â”€â”€ page.tsx             # Landing page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInterface.tsx    # Right panel â€” Q&A UI
â”‚   â”œâ”€â”€ ConditionalShell.tsx # Header/footer shell
â”‚   â”œâ”€â”€ DocumentUploader.tsx # Drag-and-drop upload
â”‚   â”œâ”€â”€ DocumentStatus.tsx   # Processing status poller
â”‚   â”œâ”€â”€ ErrorBoundary.tsx    # Panel-isolated error recovery
â”‚   â”œâ”€â”€ PDFViewer.tsx        # Left panel â€” PDF renderer
â”‚   â””â”€â”€ SplitLayout.tsx      # Two-panel orchestrator
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ adaptive-chunking.ts     # Structure-aware text splitting
â”‚   â”‚   â”œâ”€â”€ answer-generation.ts     # Multi-pass GPT-4o generation
â”‚   â”‚   â”œâ”€â”€ hybrid-search.ts         # Vector + BM25 + RRF
â”‚   â”‚   â”œâ”€â”€ ingestion-pipeline.ts    # Full pipeline orchestrator
â”‚   â”‚   â”œâ”€â”€ metadata-enrichment.ts   # AI chunk summarisation
â”‚   â”‚   â”œâ”€â”€ query-analysis.ts        # Query type classification
â”‚   â”‚   â”œâ”€â”€ reranking.ts             # Cross-encoder re-ranking
â”‚   â”‚   â””â”€â”€ self-critique.ts         # Answer validation
â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”œâ”€â”€ client.ts                # OpenAI client
â”‚   â”‚   â”œâ”€â”€ documentAnalyzer.ts      # Document type detection
â”‚   â”‚   â””â”€â”€ embeddings.ts            # Batch embedding generation
â”‚   â”œâ”€â”€ supabase/
â”‚   â”‚   â”œâ”€â”€ client.ts                # Browser client (SSR-safe)
â”‚   â”‚   â””â”€â”€ server.ts                # Server client + admin client
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ export.ts                # Markdown conversation export
â”‚       â””â”€â”€ trustScore.ts            # Confidence score utilities
â”œâ”€â”€ proxy.ts                 # Next.js 16 auth proxy (middleware)
â”œâ”€â”€ vercel.json              # Function timeout configuration
â””â”€â”€ .env.example             # Environment variable template
```

---

## Deployment

PRISM is optimised for Vercel + Supabase.

```bash
npm install -g vercel
vercel --prod
```

Set these environment variables in your Vercel project settings:

```
NEXT_PUBLIC_SUPABASE_URL
NEXT_PUBLIC_SUPABASE_ANON_KEY
SUPABASE_SERVICE_ROLE_KEY
OPENAI_API_KEY
NEXT_PUBLIC_SITE_URL        (your Vercel URL)
```

### Function timeouts

`vercel.json` configures extended timeouts for long-running operations:

| Route | Timeout | Reason |
|---|---|---|
| `/api/ingest` | 300s | 7-stage pipeline on large PDFs |
| `/api/upload` | 60s | 50MB file transfer to storage |
| `/api/chat` | 120s | 3 sequential OpenAI calls |

---

## Roadmap

- [ ] **5.1 Analytics dashboard** â€” cost tracking, feedback loop, search strategy metrics
- [ ] **Team workspaces** â€” shared document libraries with role-based access
- [ ] **Document collections** â€” group related documents, query across all of them
- [ ] **Webhook support** â€” trigger ingestion from external systems
- [ ] **OCR pipeline** â€” support for scanned PDFs via cloud OCR
- [ ] **Citation export** â€” export answers with formatted citations to Word/PDF

---

## Disclaimer

PRISM is a research and productivity tool. It is not legal advice. Always verify critical information with qualified professionals. AI answers may be incomplete or incorrect â€” use confidence scores and citations as guidance, not as authoritative sources.

---

*Built with Next.js 16, Supabase, OpenAI, and pgvector.*